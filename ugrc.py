# -*- coding: utf-8 -*-
"""UGRC.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b42GD2lmlbyEGaD-EHGE8Zc2r-PCp1jb
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler, OneHotEncoder
# import tsfel

# # Load the dataset (e.g., time series power data)
# data = pd.read_csv('synthetic_power_data.csv')

# # Extract a single column of time series data (e.g., 'power_consumption')
# time_series = data['power_consumption']

# # Extract features using TSFEL
# # Load default configuration for feature extraction
# cfg = tsfel.get_features_by_domain('all')

# # Extract features
# features = tsfel.time_series_features_extractor(cfg, time_series)

# # Display extracted features
# print(features.head())

# Load the dataset
data = pd.read_csv('synthetic_power_data.csv')

# Handle Missing Values
# Apply fillna only to numeric columns
# Identify numeric columns, NaNs and fill the NaNs with mean value
numeric_columns = data.select_dtypes(include=np.number).columns
data[numeric_columns] = data[numeric_columns].fillna(data[numeric_columns].mean())

# Step 2: Remove Outliers (Using IQR Method)
debug = True  # Set to True to print IQR debugging information

# Exclude non-continuous columns like 'holiday' from outlier removal
continuous_columns = [col for col in numeric_columns if col != 'holiday']

Q1 = data[continuous_columns].quantile(0.25)
Q3 = data[continuous_columns].quantile(0.75)
IQR = Q3 - Q1

# Relax the bounds to retain more data
lower_bound = Q1 - 3 * IQR
upper_bound = Q3 + 3 * IQR

if debug:
    print("Q1:\n", Q1)
    print("Q3:\n", Q3)
    print("Lower Bound:\n", lower_bound)
    print("Upper Bound:\n", upper_bound)

# Apply bounds to continuous columns only
data_filtered = data.copy()
for col in continuous_columns:
    data_filtered = data_filtered[(data_filtered[col] >= lower_bound[col]) & (data_filtered[col] <= upper_bound[col])]

if data_filtered.empty:
    print("Warning: Outlier removal resulted in empty DataFrame. Skipping outlier removal.")
else:
    data = data_filtered.dropna()

# Debugging: Print data shape after outlier removal
print("Data shape after outlier removal:", data.shape)

# Step 3: Normalize Numeric Data (MinMaxScaler)
if data.empty:
    raise ValueError("DataFrame is empty after preprocessing. Please check earlier steps.")

scaler = MinMaxScaler()
data_scaled = scaler.fit_transform(data[numeric_columns])

# Convert back to a DataFrame
data_scaled = pd.DataFrame(data_scaled, columns=numeric_columns)

# Step 4: Add Time-Based Features
# Convert 'timestamp' to datetime if itâ€™s not already
data['timestamp'] = pd.to_datetime(data['timestamp'])

# Add hour, weekday, and month features
data_scaled['hour'] = data['timestamp'].dt.hour
data_scaled['weekday'] = data['timestamp'].dt.weekday
data_scaled['month'] = data['timestamp'].dt.month

# Step 5: One-Hot Encode Categorical Features (e.g., weekday, month)
encoder = OneHotEncoder(sparse_output=False)
time_features = encoder.fit_transform(data_scaled[['weekday', 'month']])

# Merge encoded features back into the dataset
time_features_df = pd.DataFrame(time_features, columns=encoder.get_feature_names_out())
data_preprocessed = pd.concat([data_scaled, time_features_df], axis=1).drop(['weekday', 'month'], axis=1)

# Display the first few rows of the preprocessed data
print("Data Preprocessing Complete. Preview:")
print(data_preprocessed.head())

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
import matplotlib.pyplot as plt

# Step 1: Train-Test Split
# Separate features and target
X = data_preprocessed.drop(columns=['power_consumption'])  # Features
y = data_preprocessed['power_consumption']                # Target

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Reshape data for LSTM
X_train_reshaped = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))
X_test_reshaped = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))

# Step 2: Define and Train LSTM Model
model = Sequential([
    LSTM(64, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])),
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dense(1)  # Single output (power consumption)
])

# Compile the model
model.compile(optimizer='adam', loss='mse', metrics=['mae'])

# Train the model
history = model.fit(X_train_reshaped, y_train, epochs=20, batch_size=32, validation_data=(X_test_reshaped, y_test), verbose=1)

# Step 3: Evaluate the Model
# Make predictions
y_pred = model.predict(X_test_reshaped)

# Calculate metrics
mae = mean_absolute_error(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print(f"MAE: {mae}")
print(f"RMSE: {rmse}")

# Step 4: Generate Probabilistic Forecasts using Monte Carlo Dropout
mc_samples = 100  # Number of Monte Carlo samples
predictions = np.array([model(X_test_reshaped, training=True).numpy() for _ in range(mc_samples)])

# Calculate mean prediction and confidence intervals
mean_prediction = predictions.mean(axis=0)
lower_bound = np.percentile(predictions, 2.5, axis=0)  # 2.5th percentile for 95% confidence
upper_bound = np.percentile(predictions, 97.5, axis=0)  # 97.5th percentile for 95% confidence

# Step 5: Visualize Forecasts
plt.figure(figsize=(12, 6))
plt.plot(y_test.values, label="Actual", color="blue")
plt.plot(mean_prediction, label="Predicted", color="orange")
plt.fill_between(range(len(mean_prediction)), lower_bound.flatten(), upper_bound.flatten(), color='gray', alpha=0.3, label="95% CI")
plt.legend()
plt.title("Actual vs Predicted with Confidence Intervals")
plt.show()

!pip install optuna

import optuna
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from sklearn.metrics import mean_absolute_error

# Function to create the LSTM model with hyperparameters from Optuna
def create_model(trial):
    # Hyperparameter search space
    lstm_units = trial.suggest_int('lstm_units', 32, 128)  # LSTM units
    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)  # Dropout rate
    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)  # Learning rate
    batch_size = trial.suggest_int('batch_size', 16, 64)  # Batch size

    # Define the model
    model = Sequential([
        LSTM(lstm_units, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])),
        Dropout(dropout_rate),
        Dense(32, activation='relu'),
        Dense(1)  # Single output (power consumption)
    ])

    # Compile the model with the suggested learning rate
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='mse', metrics=['mae'])

    return model, batch_size

# Objective function to be minimized (using Optuna)
def objective(trial):
    model, batch_size = create_model(trial)

    # Train the model
    history = model.fit(X_train_reshaped, y_train,
                        epochs=10, batch_size=batch_size,
                        validation_data=(X_test_reshaped, y_test),
                        verbose=0)

    # Get predictions and calculate metrics
    y_pred = model.predict(X_test_reshaped)
    mae = mean_absolute_error(y_test, y_pred)

    return mae  # We minimize MAE (lower is better)

# Step 1: Create and Optimize the Study
study = optuna.create_study(direction='minimize')  # Minimize MAE
study.optimize(objective, n_trials=30)  # Number of trials

# Step 2: Output the Best Hyperparameters
print("Best hyperparameters found:")
print(study.best_params)

# Step 3: Train the Final Model with Best Hyperparameters
best_params = study.best_params
best_model, best_batch_size = create_model(study.best_trial)

# Train the final model with the optimal hyperparameters
history = best_model.fit(X_train_reshaped, y_train,
                         epochs=20, batch_size=best_batch_size,
                         validation_data=(X_test_reshaped, y_test),
                         verbose=1)

# Final Evaluation
y_pred_final = best_model.predict(X_test_reshaped)
final_mae = mean_absolute_error(y_test, y_pred_final)
print(f"Final MAE with optimal hyperparameters: {final_mae}")

!pip install shap

import shap
import matplotlib.pyplot as plt
import numpy as np

# Step 1: Train the Model (if not already done)
# This assumes you've trained the model in the previous steps and have a final model `best_model` trained with optimal hyperparameters.

# Step 2: Create a custom function to reshape the input for LSTM model predictions
def model_predict(input_data):
    # Reshape 2D input into 3D for LSTM (samples, time steps, features)
    input_reshaped = input_data.reshape(input_data.shape[0], 1, input_data.shape[1])
    return best_model.predict(input_reshaped)

# Step 3: SHAP Explainer
# Flatten the 3D data (X_test_reshaped) to 2D (remove the time dimension) for SHAP
X_test_flat = X_test_reshaped.reshape(X_test_reshaped.shape[0], X_test_reshaped.shape[2])

# Create a SHAP explainer object using the model_predict function (which reshapes the input for LSTM)
explainer = shap.KernelExplainer(model_predict, X_train_reshaped[:100].reshape(100, X_train_reshaped.shape[2]))  # Using a subset of training data for background

# Get SHAP values for the test set (using the flattened test data)
shap_values = explainer.shap_values(X_test_flat[:100])  # Using a subset of the test data for explanation

# Step 4: SHAP Summary Plot (Overall feature importance)
shap.summary_plot(shap_values, X_test_flat[:100], feature_names=X.columns)

# Step 5: SHAP Dependence Plot (Individual feature influence on prediction)
# Example: Influence of the first feature on model prediction
shap.dependence_plot(0, shap_values[0], X_test_flat[:100], feature_names=X.columns)

# Step 6: Visualize Model Performance Trends
# Plot actual vs predicted values
plt.figure(figsize=(12, 6))
plt.plot(y_test[:100].values, label="Actual", color="blue")
plt.plot(y_pred_final[:100], label="Predicted", color="orange")
plt.legend()
plt.title("Actual vs Predicted for Model Performance")
plt.show()

# Step 7: SHAP Force Plot (Explain a specific prediction)
# Example: Explain the first prediction from the test set
shap.initjs()  # Initializes JS visualization for force plot in Jupyter
shap.force_plot(explainer.expected_value[0], shap_values[0][0], X_test_flat[:100][0], feature_names=X.columns)

import matplotlib.pyplot as plt

# Histogram before preprocessing (raw data)
plt.figure(figsize=(10, 6))
plt.hist(data['power_consumption'], bins=30, color='skyblue', alpha=0.7, label='Before Preprocessing')
plt.xlabel('Power Consumption')
plt.ylabel('Frequency')
plt.title('Histogram of Power Consumption (Before Preprocessing)')
plt.legend()
plt.show()

# Histogram after normalization (processed data)
plt.figure(figsize=(10, 6))
plt.hist(data_preprocessed['power_consumption'], bins=30, color='orange', alpha=0.7, label='After Preprocessing')
plt.xlabel('Normalized Power Consumption')
plt.ylabel('Frequency')
plt.title('Histogram of Power Consumption (After Preprocessing)')
plt.legend()
plt.show()

# Box plot for raw data (before preprocessing)
plt.figure(figsize=(8, 6))
plt.boxplot(data['power_consumption'], vert=False, patch_artist=True, boxprops=dict(facecolor='skyblue', color='blue'))
plt.title('Box Plot of Power Consumption (Before Preprocessing)')
plt.xlabel('Power Consumption')
plt.show()

# Box plot for processed data (after normalization)
plt.figure(figsize=(8, 6))
plt.boxplot(data_preprocessed['power_consumption'], vert=False, patch_artist=True, boxprops=dict(facecolor='orange', color='red'))
plt.title('Box Plot of Power Consumption (After Preprocessing)')
plt.xlabel('Normalized Power Consumption')
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# Select relevant numeric columns for correlation (excluding one-hot encoded features if not needed)
numeric_features = ['power_consumption', 'temperature', 'holiday', 'hour'] + \
                   [col for col in data_preprocessed.columns if 'weekday_' in col or 'month_' in col]

# Compute the correlation matrix
correlation_matrix = data_preprocessed[numeric_features].corr()

# Plot the heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', cbar=True)
plt.title('Heatmap of Feature Correlations (After Preprocessing)')
plt.show()

# Plot training and validation loss
plt.figure(figsize=(10, 6))
plt.plot(history.history['loss'], label='Training Loss', color='blue')
plt.plot(history.history['val_loss'], label='Validation Loss', color='orange')
plt.xlabel('Epochs')
plt.ylabel('Loss (MSE)')
plt.title('Training and Validation Loss Over Epochs')
plt.legend()
plt.show()

# Monte Carlo Dropout Predictions
mc_samples = 100
predictions = np.array([best_model.predict(X_test_reshaped) for _ in range(mc_samples)])

# Compute mean prediction and confidence intervals
mean_prediction = predictions.mean(axis=0).flatten()
lower_bound = np.percentile(predictions, 2.5, axis=0).flatten()
upper_bound = np.percentile(predictions, 97.5, axis=0).flatten()

# Plot actual vs predicted with confidence intervals
plt.figure(figsize=(12, 6))
plt.plot(y_test.values, label='Actual', color='blue')
plt.plot(mean_prediction, label='Predicted', color='orange')
plt.fill_between(range(len(mean_prediction)), lower_bound, upper_bound, color='gray', alpha=0.3, label='95% CI')
plt.xlabel('Time')
plt.ylabel('Power Consumption')
plt.title('Actual vs Predicted with Confidence Intervals')
plt.legend()
plt.show()

# Zoomed-in section (e.g., first 100 points)
zoom_range = 100  # Adjust as needed
plt.figure(figsize=(12, 6))
plt.plot(y_test.values[:zoom_range], label='Actual', color='blue')
plt.plot(mean_prediction[:zoom_range], label='Predicted', color='orange')
plt.fill_between(range(zoom_range), lower_bound[:zoom_range], upper_bound[:zoom_range], color='gray', alpha=0.3, label='95% CI')
plt.xlabel('Time')
plt.ylabel('Power Consumption')
plt.title('Zoomed-In: Actual vs Predicted with Confidence Intervals')
plt.legend()
plt.show()

import optuna.visualization as vis

# Plot optimization history
optuna_history = vis.plot_optimization_history(study)
optuna_history.show()



# Plot hyperparameter importance
optuna_importance = vis.plot_param_importances(study)
optuna_importance.show()

# Print the best hyperparameters and corresponding performance
print("Best Hyperparameters Found:")
print(study.best_params)
print(f"Best MAE: {study.best_value}")

# Plot training and validation loss of the final model
plt.figure(figsize=(10, 6))
plt.plot(history.history['loss'], label='Training Loss', color='blue')
plt.plot(history.history['val_loss'], label='Validation Loss', color='orange')
plt.xlabel('Epochs')
plt.ylabel('Loss (MSE)')
plt.title('Training and Validation Loss with Best Hyperparameters')
plt.legend()
plt.show()